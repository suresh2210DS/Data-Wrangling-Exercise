---
author: "Suresh Gopalakrishnan"
date: "January 30, 2018"
output: pdf_document
dev: 'png'
number_sections: true
fig_width: 7
fig_height: 4.5
theme: "cosmo"
linkcolor: "cyan"
---


# Capstone Milestone Report - Data Wrangling
Suresh  
Date- `r Sys.Date()`  

```{r fig.align = 'default', warning = FALSE, out.width="100%", echo=FALSE}
knitr::include_graphics("Taxi2.jpg", auto_pdf = TRUE)
```

```{r Set_memory, message=FALSE, echo=FALSE, results='hide', include=FALSE}
# to resolve memory issue
memory.limit(size = 56000)
```
 
```{r remove_junk, message=FALSE, echo=FALSE, include=FALSE}
# to resolve ggmap table error during execution.
if (exists(".GeocodedInformation")) {
  rm(.GeocodedInformation)
}
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r echo=FALSE,message=FALSE}
## Function to display multiple plot
## REF -> http://stat545.com/block020_multiple-plots-on-a-page.html#use-the-multiplot-function
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  require(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots <- length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(
      seq(1, cols * ceiling(numPlots / cols)),
      ncol = cols, nrow = ceiling(numPlots / cols)
    )
  }

  if (numPlots == 1) {
    print(plots[[1]])
  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(
        layout.pos.row = matchidx$row,
        layout.pos.col = matchidx$col
      ))
    }
  }
}
```

### Introduction  

New York City taxi rides paint a vibrant picture of life in the city. The millions of rides taken each month can provide insight into traffic patterns, road blockage, or large-scale events that attract many New Yorkers. With ridesharing apps gaining popularity, it is increasingly important for taxi companies to provide visibility to their estimated fare and
ride duration, since the competing apps provide these metrics upfront. Predicting fare and duration of a ride can help passengers decide when is the optimal time to start their commute.

The primary goal of this project is to predict trip duration of NYC Taxis based on features like trip coordinates, duration date and time. The data for this project is from Kaggle, [NYC Taxi Ride Duration](https://www.kaggle.com/c/nyc-taxi-trip-duration) competition.  


### The Data 

We are using totally 4 datasets for our Exploratory analysis and modeling. 2 data namely Train and Test are published by Kaggle. We are also using OSRM Open Source Routing Machine for analysis. We are not going to use OSRM in initial Data Wrangling. Let's dive in to our data sets to understand the features. 


#### Load Required Packages

Before we start analyzing dataset features, lets load the packages needed for Data Wrangling. Predominently we have used dplyr, ggplot2, ggmap and lubridate thoughtout our analysis. 

```{r message=FALSE, warning=FALSE}

library(dplyr)
library(tidyr)
library(lubridate)
library(ggplot2)
library(ggmap)
library(stringr)
library(RColorBrewer)  
library(geosphere)
library(tibble)
library(forcats)
library(maps)
library(readr)
```


#### Data Wrangling and Cleaning

For our intial Data Wrangling we are using the training and test datasets provided by Kaggle. Training dataset has close to 1.5 Million and 630k records in test dataset. Each row contains one taxi trip. 

```{r message=FALSE, warning=FALSE}
taxi <- read_csv("train.csv")
test <- read_csv("test.csv")
glimpse(taxi)
glimpse(test)
taxi <- data.frame(taxi)
test <- data.frame(test)
```

We see below observations on Taxi and Test Records  

* Trip *Id* is unique identification of a trip

* *vendor_id*  field has only 2 values "1" or "2" asuming two taxi companies  

* *pickup/dropoff_datetime* - holds date and time of pickup and dropoff. we need to mutate the fields to get date and time seperately.  

* *pickup/dropoff_longitute/latitute* - hold values of geographical coordinates where the meter was activate/deactivated.  

* *store_and_fwd_flag* is a flag that indicates whether the trip data was sent immediately to the vendor ("N") or held in the memory of the taxi because there was no connection to the server ("Y"). Maybe there could be a correlation with certain geographical areas with bad   reception?  

* *trip_duration* hold the duration in seconds and its our target prediction of ths project. 

* Please note Test data will not have actual trip duration data. We have to submit the data in Kaggle to know the model score. 

 
#### Check blank values in TAXI 

```{r}
sum(is.na(taxi))
sum(is.na(test))
```


#### Reformating data 

For our analysis, we will date fields from characters into date objects. We also change vendor_id as a factor. This makes it easier to visualise relationships that involve these features.


```{r}
taxi <- taxi %>% mutate(
  pickup_datetime = ymd_hms(pickup_datetime),
  dropoff_datetime = ymd_hms(dropoff_datetime),
  vendor_id = factor(vendor_id),
  passenger_count = factor(passenger_count)
)
```


#### Consistency check

This code is to check *trip_durations* are consistent with the intervals between  *pickup_datetime* and *dropoff_datetime*.  

Actual count of Taxi file is `r count(taxi)`. Count of below check should the same else the records are inconsistent.  

```{r}
taxi %>%
  mutate(check = abs(int_length(interval(dropoff_datetime, pickup_datetime)) + trip_duration) > 0) %>%
  select(check, pickup_datetime, dropoff_datetime, trip_duration) %>%
  group_by(check) %>%
  count()
```

#### Feature Visualizations

We are starting with NYC Map to check where the most of pickup and dropoff are happening. We took 5000 samples from Taxi file and plotted.  It turns out that almost all of our trips were in fact taking place in Manhattan only.  

```{r fig.align = 'default', warning = FALSE, out.width="100%", message=FALSE}

my_map <- get_map(location = "New York City", zoom = 12, maptype = "roadmap", source = "google", color = "color")
set.seed(1234)
tax_samp <- sample_n(taxi, 5000)
ggmap(my_map) +
  geom_point(data = tax_samp, aes(x = pickup_longitude, y = pickup_latitude), size = 0.3, alpha = 0.3, color = "blue") +
  geom_point(data = tax_samp, aes(x = dropoff_longitude, y = dropoff_latitude), size = 0.3, alpha = 0.3, color = "red") +
  theme(axis.ticks = element_blank(), axis.text = element_blank())
```

Below analysis to check if any abnormal trip duration exists in our data. 

```{r}
taxi %>%
  arrange(desc(trip_duration)) %>%
  select(trip_duration, pickup_datetime, dropoff_datetime) %>%
  head(5)

taxi %>%
  arrange(desc(trip_duration)) %>%
  select(trip_duration, pickup_datetime, dropoff_datetime) %>%
  tail(5)
```

Lets check the distributions of pickup_datetime and dropoff_datetime by year. 

```{r message=FALSE}
p1 <- taxi %>%
  ggplot(aes(x = pickup_datetime)) +
  geom_histogram(fill = "red", colour = "white", bins = 180) +
  scale_x_datetime(date_breaks = "1 week", date_labels = "%W%b") +
  labs(x = "Pickup dates week/month") +
  theme(axis.text.x = element_text(angle = 90))

p2 <- taxi %>%
  ggplot(aes(dropoff_datetime)) +
  geom_histogram(fill = "blue", colour = "white", bins = 180) +
  scale_x_datetime(date_breaks = "1 week", date_labels = "%W%b") +
  labs(x = "Dropoff dates week/month") +
  theme(axis.text.x = element_text(angle = 90))

layout <- matrix(c(1, 2), 2, 1, byrow = FALSE)
multiplot(p1, p2, layout = layout)
```


In the below plot we are checking passenger count, vendor_id, total number of pickups on hour/day distribution. 

```{r echo=FALSE,fig.align = 'default', warning = FALSE, out.width="100%", message=FALSE}
P1 <- taxi %>%
  group_by(passenger_count) %>%
  count() %>%
  ggplot(aes(passenger_count, n, fill = passenger_count)) +
  geom_col() +
  scale_y_sqrt() + scale_fill_brewer(palette = "Set1") +
  labs(x = "Passenger Count", y = "Total number of pickups") +
  theme(legend.position = "none")

P2 <- taxi %>%
  ggplot(aes(vendor_id, fill = vendor_id)) +
  geom_bar(position = "dodge") +
  scale_fill_brewer(palette = "Set1") +
  theme(legend.position = "none")

P3 <- taxi %>%
  ggplot(aes(store_and_fwd_flag, fill = vendor_id)) +
  geom_bar(stat = "count", position = "dodge", alpha = 0.6) +
  theme(legend.position = "none") +
  scale_y_log10()

P4 <- taxi %>%
  mutate(wday = wday(pickup_datetime, label = TRUE)) %>%
  group_by(wday, vendor_id) %>%
  count() %>%
  ggplot(aes(wday, n, fill = vendor_id)) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_brewer(palette = "Set1") +
  labs(x = "Day of the week", y = "Total number of pickups") +
  theme(legend.position = "none")

P5 <- taxi %>%
  mutate(hpick = hour(pickup_datetime)) %>%
  group_by(hpick) %>%
  count() %>%
  ggplot(aes(hpick, n)) +
  geom_smooth(method = "loess", span = 1 / 2) +
  geom_point(size = 4, colour = "blue") +
  labs(x = "Hour of the day", y = "Total number of pickups") +
  theme(legend.position = "none")

layout <- matrix(c(1, 2, 3, 4, 5, 5), 3, 2, byrow = TRUE)
multiplot(P1, P2, P3, P4, P5, layout = layout)
```


* We found some abnormal trip with zero passenger and more 7 passengers  
* We find an interesting pattern with Monday being the quietest day and Friday very busy.  
* we find evening hours are busiest hours of the day.  

Now lets check how the trends in different vizualization.   

* We find Jan and June has less number of trips 
* We find During weekends early morning are busy 

```{r fig.align = 'default', warning = FALSE, out.width="100%", message=FALSE}
p1 <- taxi %>%
  mutate(
    hpick = hour(pickup_datetime),
    Month = factor(month(pickup_datetime, label = TRUE))
  ) %>%
  group_by(hpick, Month) %>%
  count() %>%
  ggplot(aes(hpick, n, color = Month)) +
  geom_line(size = 1.5) +
  labs(x = "Hour of the day", y = "count")

p2 <- taxi %>%
  mutate(
    hpick = hour(pickup_datetime),
    wday = factor(wday(pickup_datetime, label = TRUE))
  ) %>%
  group_by(hpick, wday) %>%
  count() %>%
  ggplot(aes(hpick, n, color = wday)) +
  geom_line(size = 1.5) +
  labs(x = "Hour of the day", y = "count")

layout <- matrix(c(1, 2), 2, 1, byrow = FALSE)
multiplot(p1, p2, layout = layout)
```

#### In the next slides we trying find the relation between the trip duration and picking up data & time. This will help us identify how strongly correlated to add them in the model. 

```{r fig.align = 'default', warning = FALSE, out.width="100%", message=FALSE}
p1 <- taxi %>%
  mutate(wday = wday(pickup_datetime, label = TRUE)) %>%
  group_by(wday, vendor_id) %>%
  summarise(median_duration = median(trip_duration) / 60) %>%
  ggplot(aes(wday, median_duration, color = vendor_id)) +
  geom_point(size = 4) +
  scale_colour_brewer(palette = "Set1") +
  labs(x = "Day of the week", y = "Median duration [min]") +
  theme(panel.background = element_rect(fill = "white"))

p2 <- taxi %>%
  mutate(pickt = hour(pickup_datetime)) %>%
  group_by(pickt, vendor_id) %>%
  summarise(median_duration = median(trip_duration) / 60) %>%
  ggplot(aes(pickt, median_duration, color = vendor_id)) +
  geom_smooth(method = "loess", span = 1 / 2) +
  geom_point(size = 4) +
  scale_colour_brewer(palette = "Set1") +
  labs(x = "Hour of the day", y = "Median duration [min]") +
  theme(legend.position = "none")

layout <- matrix(c(1, 2), 2, 1, byrow = FALSE)
multiplot(p1, p2, layout = layout)
```

In the our next slide, we are checking for any correlation between passenger count and trip duration. 

```{r fig.align = 'default', warning = FALSE, out.width="100%", message=FALSE}
taxi %>%
  group_by(passenger_count, vendor_id) %>%
  summarise(median_duration = median(trip_duration) / 60) %>%
  ggplot(aes(passenger_count, median_duration, fill = passenger_count)) +
  geom_bar(stat = "identity") +
  scale_y_log10() +
  theme(legend.position = "none") +
  facet_wrap(~ vendor_id) +
  labs(y = "Trip duration", x = "Number of passengers")
```


#### Relation between Time and Direct distance

In this section we are trying to find out the relation between drip duration and direct distance. To derive direct distance, we are using "Geosphere" package. Also, we are trying to find out any significance counts trips made out of Manhattan. Two major airports attract more taxi rides from city. We need to find how significant they are for our modelling.  

```{r echo=FALSE}
jfk_coord <- tibble(lon = -73.778889, lat = 40.639722)
la_guardia_coord <- tibble(lon = -73.872611, lat = 40.77725)

pick_coord <- taxi %>%
  select(pickup_longitude, pickup_latitude)
drop_coord <- taxi %>%
  select(dropoff_longitude, dropoff_latitude)

taxi$dist <- distCosine(pick_coord, drop_coord)
taxi$jfk_dist_pick <- distCosine(pick_coord, jfk_coord)
taxi$jfk_dist_drop <- distCosine(drop_coord, jfk_coord)
taxi$lg_dist_pick <- distCosine(pick_coord, la_guardia_coord)
taxi$lg_dist_drop <- distCosine(drop_coord, la_guardia_coord)

taxi <- taxi %>%
  mutate(
    speed = (dist / trip_duration * 2.236),
    date = date(pickup_datetime),
    month = month(pickup_datetime, label = TRUE),
    wday = wday(pickup_datetime, label = TRUE),
    wday = fct_relevel(wday, c("Mon", "Tues", "Wed", "Thurs", "Fri", "Sat", "Sun")),
    hour = hour(pickup_datetime),
    work = (hour %in% seq(8, 18)) & (wday %in% c("Mon", "Tues", "Wed", "Thurs", "Fri")),
    jfk_trip = (jfk_dist_pick < 2e3) | (jfk_dist_drop < 2e3),
    lg_trip = (lg_dist_pick < 2e3) | (lg_dist_drop < 2e3)
  )
```

Lets plot relationship trip duration and distance

```{r fig.align = 'default', warning = FALSE, out.width="100%", message=FALSE}
set.seed(1234)
taxi %>%
  sample_n(5000) %>%
  ggplot(aes(dist, trip_duration)) +
  geom_point(color = "blue", alpha = 0.4) +
  scale_x_log10() +
  scale_y_log10() +
  labs(x = "Direct distance[meters]", y = "Trip duration[seconds]")
```

* Its clear observation, that distance increases trip duration. 

Lets visualize how speed new york taxis travelling during peak hours and weekends. In order to find bogus values in the datasets, we can find extreme speed records and eliminate them 

```{r}
taxi %>%
  ggplot(aes(speed)) +
  geom_histogram(fill = "purple", bins = 50) +
  scale_x_continuous(limits = c(0, 100)) +
  labs(x = "Average speed [Miles/hr] (direct distance)")
```

Plotting speed on different times using heat map. 

```{r fig.align = 'default', warning = FALSE, out.width="100%", message=FALSE}
P1 <- taxi %>%
  group_by(wday, hour) %>%
  summarise(median_speed = median(speed)) %>%
  ggplot(aes(hour, wday, fill = median_speed)) +
  geom_tile() +
  labs(x = "Hour of the day", y = "Day of the week") +
  scale_fill_distiller(palette = "Spectral")
layout <- matrix(c(1, 1), 1, 1, byrow = TRUE)
multiplot(P1, layout = layout)
```

#### Data Cleaning.

The aim here is to remove trips that have improbable features, such as extreme trip durations or very low average speed.

** Filter trips more than 24 hours. 

```{r}
long_hrtrips <- taxi %>%
  filter(trip_duration > 24 * 3600)

long_hrtrips %>%
  arrange(desc(dist)) %>%
  select(pickup_datetime, dropoff_datetime, speed) %>%
  head(05)
```

** Filter trips shorter than a few minutes

```{r}
min_trips <- taxi %>%
  filter(trip_duration < 5 * 60)

min_trips %>%
  arrange(dist) %>%
  select(dist, pickup_datetime, dropoff_datetime, speed) %>%
  head(05)
```

** Find trip with zero miles 

```{r}
zero_dist <- taxi %>%
  filter(near(dist, 0))
nrow(zero_dist)
```

#### Filter all bogus data from taxi dataset

```{r}
taxi <- taxi %>%
  filter(
    trip_duration < 22 * 3600,
    dist > 0 | (near(dist, 0) & trip_duration < 60),
    jfk_dist_pick < 3e5 & jfk_dist_drop < 3e5,
    trip_duration > 10,
    speed < 100
  )
```


#### Write the records to output file 

```{r}
taxi %>% write_csv("Taxi_Clean.csv")
```

#### Next Steps 

Above analysis helped us to understand the structure of data, values, trends in the data. We were able to filter the data for modelling. As a next step, we will introduce external data and try to find features will help model the data. 

